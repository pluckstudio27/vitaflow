# Sistema de Testes Automatizados - Almox SMS

Este diretÃ³rio contÃ©m um sistema abrangente de testes automatizados para a aplicaÃ§Ã£o Almox SMS.

## ðŸ“ Estrutura dos Testes

```
tests/
â”œâ”€â”€ conftest.py                 # ConfiguraÃ§Ãµes e fixtures do pytest
â”œâ”€â”€ test_auth.py               # Testes de autenticaÃ§Ã£o e autorizaÃ§Ã£o
â”œâ”€â”€ test_api_users.py          # Testes da API de usuÃ¡rios
â”œâ”€â”€ test_api_categories.py     # Testes da API de categorias
â”œâ”€â”€ test_api_products.py       # Testes da API de produtos
â”œâ”€â”€ test_api_stock.py          # Testes da API de estoque
â”œâ”€â”€ test_web_pages.py          # Testes das pÃ¡ginas web
â”œâ”€â”€ test_report_generator.py   # Gerador de relatÃ³rios personalizados
â””â”€â”€ README.md                  # Esta documentaÃ§Ã£o
```

## ðŸš€ Como Executar os Testes

### ExecuÃ§Ã£o Completa

Para executar todos os testes e gerar relatÃ³rios completos:

```bash
python run_tests.py
```

### ExecuÃ§Ã£o por Tipo

Execute apenas tipos especÃ­ficos de teste:

```bash
# Testes de autenticaÃ§Ã£o
python run_tests.py --type auth

# Testes de API
python run_tests.py --type api

# Testes de pÃ¡ginas web
python run_tests.py --type web

# Testes unitÃ¡rios
python run_tests.py --type unit

# Testes de integraÃ§Ã£o
python run_tests.py --type integration

# Testes lentos
python run_tests.py --type slow
```

### OpÃ§Ãµes AvanÃ§adas

```bash
# ExecuÃ§Ã£o verbosa
python run_tests.py --verbose

# Pular anÃ¡lise de cobertura
python run_tests.py --no-coverage

# Pular testes de performance
python run_tests.py --no-performance

# Pular verificaÃ§Ã£o de saÃºde
python run_tests.py --no-health
```

### ExecuÃ§Ã£o Manual com Pytest

```bash
# Todos os testes
pytest tests/

# Testes especÃ­ficos
pytest tests/test_auth.py

# Com cobertura
pytest --cov=. tests/

# Com relatÃ³rio HTML
pytest --html=report.html tests/
```

## ðŸ“Š Tipos de Teste

### ðŸ” Testes de AutenticaÃ§Ã£o (`test_auth.py`)
- Login/logout
- ProteÃ§Ã£o de rotas
- Controle de acesso por nÃ­vel de usuÃ¡rio
- ValidaÃ§Ã£o de sessÃµes

### ðŸ‘¥ Testes de API de UsuÃ¡rios (`test_api_users.py`)
- CRUD de usuÃ¡rios
- ValidaÃ§Ã£o de dados
- Controle de acesso
- PaginaÃ§Ã£o e busca

### ðŸ·ï¸ Testes de API de Categorias (`test_api_categories.py`)
- CRUD de categorias
- ValidaÃ§Ã£o de cÃ³digos Ãºnicos
- Controle de acesso administrativo
- Relacionamentos com produtos

### ðŸ“¦ Testes de API de Produtos (`test_api_products.py`)
- CRUD de produtos
- Filtros por categoria
- ValidaÃ§Ã£o de dados
- Controle de acesso por categoria do usuÃ¡rio

### ðŸ“Š Testes de API de Estoque (`test_api_stock.py`)
- CRUD de estoque
- MovimentaÃ§Ãµes
- RelatÃ³rios
- Alertas de estoque baixo

### ðŸŒ Testes de PÃ¡ginas Web (`test_web_pages.py`)
- Carregamento de pÃ¡ginas
- Elementos da interface
- Responsividade
- Acessibilidade
- Performance

## ðŸ› ï¸ ConfiguraÃ§Ã£o

### DependÃªncias

Instale as dependÃªncias de teste:

```bash
pip install -r requirements.txt
```

As dependÃªncias de teste incluem:
- `pytest` - Framework de testes
- `pytest-flask` - IntegraÃ§Ã£o Flask/pytest
- `pytest-cov` - Cobertura de cÃ³digo
- `pytest-html` - RelatÃ³rios HTML
- `pytest-mock` - Mocking
- `coverage` - AnÃ¡lise de cobertura
- `factory-boy` - Factories para dados de teste
- `faker` - GeraÃ§Ã£o de dados falsos

### ConfiguraÃ§Ã£o do Banco de Dados

Os testes usam um banco SQLite temporÃ¡rio em memÃ³ria para isolamento completo.

### VariÃ¡veis de Ambiente

Configure as seguintes variÃ¡veis para testes:

```bash
export FLASK_ENV=testing
export DATABASE_URL=sqlite:///:memory:
export SECRET_KEY=test-secret-key
```

## ðŸ“ˆ RelatÃ³rios

O sistema gera mÃºltiplos tipos de relatÃ³rio:

### ðŸ“„ RelatÃ³rio HTML
- Interface visual interativa
- GrÃ¡ficos de cobertura
- Detalhes de cada teste
- MÃ©tricas de performance

### ðŸ“Š RelatÃ³rio JSON
- Dados estruturados
- IntegraÃ§Ã£o com CI/CD
- AnÃ¡lise programÃ¡tica

### ðŸ“ RelatÃ³rio Markdown
- DocumentaÃ§Ã£o legÃ­vel
- IntegraÃ§Ã£o com Git
- FÃ¡cil compartilhamento

### ðŸ“‹ RelatÃ³rio de Cobertura
- Cobertura por arquivo
- Linhas nÃ£o cobertas
- RelatÃ³rio HTML detalhado

## ðŸŽ¯ Fixtures DisponÃ­veis

### AplicaÃ§Ã£o e Cliente
- `app` - InstÃ¢ncia da aplicaÃ§Ã£o Flask
- `client` - Cliente de teste Flask
- `runner` - Runner de comandos CLI

### Banco de Dados
- `db_session` - SessÃ£o de banco limpa
- `clean_db` - Banco limpo antes de cada teste

### Dados de Teste
- `central_teste` - Central de teste
- `categoria_teste` - Categoria de teste
- `categoria_teste_2` - Segunda categoria
- `usuario_admin` - UsuÃ¡rio administrador
- `usuario_user` - UsuÃ¡rio comum
- `produto_teste` - Produto de teste
- `almoxarifado_teste` - Item de estoque

### AutenticaÃ§Ã£o
- `auth_headers_admin` - Headers de autenticaÃ§Ã£o admin
- `auth_headers_user` - Headers de autenticaÃ§Ã£o usuÃ¡rio
- `admin_logged_in` - SessÃ£o admin ativa
- `user_logged_in` - SessÃ£o usuÃ¡rio ativa

## ðŸ·ï¸ Marcadores (Markers)

Use marcadores para categorizar testes:

```python
@pytest.mark.unit          # Testes unitÃ¡rios
@pytest.mark.integration   # Testes de integraÃ§Ã£o
@pytest.mark.api          # Testes de API
@pytest.mark.web          # Testes de interface web
@pytest.mark.auth         # Testes de autenticaÃ§Ã£o
@pytest.mark.slow         # Testes lentos
```

## ðŸ“ Escrevendo Novos Testes

### Estrutura BÃ¡sica

```python
import pytest

@pytest.mark.api
class TestMinhaAPI:
    """Testes para minha API"""
    
    def test_minha_funcionalidade(self, client, auth_headers_admin):
    """Teste de exemplo"""
    response = client.get('/api/endpoint', headers=auth_headers_admin)
    assert response.status_code == 200
        data = response.get_json()
        assert 'campo_esperado' in data
```

### Boas PrÃ¡ticas

1. **Nomes Descritivos**: Use nomes que descrevam claramente o que estÃ¡ sendo testado
2. **Isolamento**: Cada teste deve ser independente
3. **Arrange-Act-Assert**: Organize o cÃ³digo do teste em seÃ§Ãµes claras
4. **Fixtures**: Use fixtures para dados de teste reutilizÃ¡veis
5. **Marcadores**: Categorize testes com marcadores apropriados

### Testando APIs

```python
def test_create_resource(self, client, auth_headers_admin):
    """Teste criaÃ§Ã£o de recurso"""
    data = {'nome': 'Teste', 'ativo': True}
    response = client.post('/api/recursos',
                          headers=auth_headers_admin,
                          json=data)
    assert response.status_code == 201
    result = response.get_json()
    assert result['nome'] == data['nome']
```

### Testando PÃ¡ginas Web

```python
def test_page_loads(self, client, admin_logged_in):
    """Teste carregamento de pÃ¡gina"""
    response = client.get('/pagina')
    assert response.status_code == 200
    assert b'conteudo_esperado' in response.data
```

## ðŸ”§ Troubleshooting

### Problemas Comuns

1. **Testes Falhando por DependÃªncias**
   - Verifique se todas as dependÃªncias estÃ£o instaladas
   - Execute `pip install -r requirements.txt`

2. **Erro de Banco de Dados**
   - Verifique se o SQLite estÃ¡ disponÃ­vel
   - Confirme que nÃ£o hÃ¡ conflitos de schema

3. **Testes Lentos**
   - Use marcador `@pytest.mark.slow` para testes demorados
   - Execute testes rÃ¡pidos com `pytest -m "not slow"`

4. **Problemas de AutenticaÃ§Ã£o**
   - Verifique se as fixtures de autenticaÃ§Ã£o estÃ£o sendo usadas
   - Confirme que o SECRET_KEY estÃ¡ configurado

### Debug

Para debug detalhado:

```bash
# ExecuÃ§Ã£o com output detalhado
pytest -v -s tests/

# Parar no primeiro erro
pytest -x tests/

# Debug com pdb
pytest --pdb tests/
```

## ðŸ“ž Suporte

Para dÃºvidas sobre os testes:

1. Consulte esta documentaÃ§Ã£o
2. Verifique os exemplos nos arquivos de teste
3. Execute `pytest --help` para opÃ§Ãµes do pytest
4. Consulte a documentaÃ§Ã£o oficial do pytest

## ðŸ”„ IntegraÃ§Ã£o ContÃ­nua

Para integrar com CI/CD:

```yaml
# Exemplo GitHub Actions
- name: Run Tests
  run: |
    python run_tests.py --no-performance
    
- name: Upload Coverage
  uses: codecov/codecov-action@v1
  with:
    file: test_reports/coverage.xml
```

## ðŸ“Š MÃ©tricas de Qualidade

O sistema monitora:

- **Cobertura de CÃ³digo**: Meta > 80%
- **Taxa de Sucesso**: Meta > 95%
- **Performance**: APIs < 500ms
- **Qualidade**: Zero erros crÃ­ticos

---

**Ãšltima atualizaÃ§Ã£o**: Janeiro 2024  
**VersÃ£o**: 1.0.0